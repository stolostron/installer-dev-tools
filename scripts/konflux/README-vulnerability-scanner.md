# OpenShift Cluster Vulnerability Scanner

## Overview

`scan-cluster-vulnerabilities.sh` is a comprehensive vulnerability scanning tool for OpenShift clusters. It uses **Trivy** (by Aqua Security) to scan all container images running in your cluster and generate detailed vulnerability reports.

## Why Trivy?

After evaluating multiple solutions for OpenShift environments, **Trivy** is recommended because:

### Available Solutions Comparison

| Solution | Type | Pros | Cons | Best For |
|----------|------|------|------|----------|
| **Trivy** ⭐ | CLI/Open Source | Fast, comprehensive CVE DB, easy install, multiple formats | Requires external tool | Quick scans, CI/CD, CLI workflows |
| RHACS/StackRox | Commercial | Native OpenShift integration, real-time | Requires subscription, heavy | Enterprise with Red Hat support |
| Grype | CLI/Open Source | Fast, good matching | Requires installation | Alternative to Trivy |
| Clair | API/Open Source | Integrated with Quay | Complex setup, needs database | Quay registry integration |
| Skopeo | Native | Already in OpenShift | Limited vulnerability detection | Basic image inspection |

**Recommendation: Trivy** offers the best balance of features, ease of use, and comprehensive vulnerability detection for OpenShift environments.

## Features

✅ **Automatic Trivy Installation** - Downloads and installs Trivy if not present
✅ **Cluster-Wide Scanning** - Scans all images across all namespaces
✅ **Namespace Filtering** - Target specific namespaces
✅ **Severity Filtering** - Focus on CRITICAL/HIGH or include all levels
✅ **Multiple Output Formats** - table, JSON, SARIF, CycloneDX, SPDX
✅ **Detailed Reports** - Per-image vulnerability reports
✅ **Summary Reports** - Aggregate statistics and trends
✅ **Offline Mode** - Scan without internet connectivity
✅ **Parallel Scanning** - Speed up large cluster scans
✅ **Image Filtering** - Scan only images matching patterns

## Installation

No installation required! The script will:
1. Check if Trivy is installed
2. Download and install it automatically if missing
3. Install to `~/.local/bin/trivy`

### Manual Trivy Installation (Optional)

If you prefer to install Trivy manually:

```bash
# macOS
brew install trivy

# Linux (download binary)
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

# Container
docker pull aquasec/trivy:latest
```

## Prerequisites

- OpenShift CLI (`oc`) installed
- Logged into an OpenShift cluster (`oc login`)
- Internet connectivity (for initial Trivy DB download)
- `jq` installed for JSON processing

## Usage

### Basic Examples

```bash
# Scan all images in the cluster (CRITICAL and HIGH severity only)
./scan-cluster-vulnerabilities.sh

# Scan specific namespace
./scan-cluster-vulnerabilities.sh --namespace openshift-gitops

# Scan with all severity levels
./scan-cluster-vulnerabilities.sh --severity UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL

# Generate JSON output for automation
./scan-cluster-vulnerabilities.sh --format json

# Detailed scan with per-image reports
./scan-cluster-vulnerabilities.sh --detailed

# Scan only ACM images
./scan-cluster-vulnerabilities.sh --image-filter "acm-d"

# Include vulnerabilities without fixes
./scan-cluster-vulnerabilities.sh --include-unfixed

# Offline scan (after DB is cached)
./scan-cluster-vulnerabilities.sh --offline
```

### Advanced Examples

```bash
# Scan specific namespace with detailed reports
./scan-cluster-vulnerabilities.sh \
  --namespace crt-redhat-acm-tenant \
  --severity CRITICAL,HIGH \
  --detailed \
  --format json

# Scan multiple namespaces (run separately)
for ns in openshift-gitops openshift-operators kube-system; do
  ./scan-cluster-vulnerabilities.sh --namespace $ns --output-dir reports/$ns
done

# Custom Trivy DB repository (air-gapped environments)
./scan-cluster-vulnerabilities.sh \
  --trivy-db-repo myregistry.com/trivy-db \
  --offline

# Fast scan of specific images
./scan-cluster-vulnerabilities.sh \
  --image-filter "quay.io/acm-d" \
  --severity CRITICAL \
  --timeout 120
```

## Output

### Directory Structure

```
vulnerability-reports/
├── vulnerability-summary-20251031-143022.txt              # Human-readable summary
├── vulnerability-summary-20251031-143022.json             # Machine-readable summary
├── detailed-vulnerabilities-20251031-143022.csv           # CVE details (NEW!)
├── quay.io_acm-d_console_sha256_abc123-20251031-143022.json  # Per-image report (if --detailed)
├── quay.io_acm-d_search-api_sha256_def456-20251031-143022.json
└── ...
```

### CVE Details Report (CSV) - **NEW!**

The detailed CVE report provides actionable information for security teams:

```csv
Image,CVE ID,Severity,CVSS Score,Package Name,Installed Version,Fixed Version,Title
"quay.io/acm-d/console@sha256:abc","CVE-2024-1234","CRITICAL",9.8,"openssl","1.1.1k","1.1.1l","OpenSSL vulnerability allows remote code execution"
"quay.io/acm-d/console@sha256:abc","CVE-2024-5678","HIGH",7.5,"libcurl","7.68.0","7.68.1","Buffer overflow in curl"
"quay.io/acm-d/search-api@sha256:def","CVE-2024-9012","CRITICAL",10.0,"log4j","2.14.0","2.17.1","Log4Shell remote code execution"
```

**Use this report to:**
- Identify which images need rebuilding
- Prioritize fixes by CVSS score
- Track unfixable vulnerabilities
- Generate security compliance reports
- Import into spreadsheets or databases

### Summary Report (Text)

```
OpenShift Cluster Vulnerability Scan Report
Generated: Fri Oct 31 14:30:22 EDT 2025
Namespace: All namespaces
Severity Filter: CRITICAL,HIGH
Total Images Scanned: 47

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

quay.io/acm-d/console@sha256:abc123 - CLEAN
quay.io/acm-d/search-api@sha256:def456
  CRITICAL: 2
  HIGH: 5
  MEDIUM: 0
  LOW: 0
  UNKNOWN: 0

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

TOP CRITICAL VULNERABILITIES (Sample)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

CVE-2024-1234 (CVSS: 9.8)
  Image: quay.io/acm-d/search-api@sha256:def456
  Package: openssl
  Fixed Version: 1.1.1l

CVE-2024-9012 (CVSS: 10.0)
  Image: quay.io/acm-d/search-api@sha256:def456
  Package: log4j
  Fixed Version: 2.17.1

For complete CVE details, see: detailed-vulnerabilities-20251031-143022.csv

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

SUMMARY
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Total Images Scanned: 47
  - With Vulnerabilities: 23
  - Clean: 22
  - Failed: 2

Total Vulnerabilities Found:
  - CRITICAL: 15
  - HIGH: 42
  - MEDIUM: 0
  - LOW: 0
  - UNKNOWN: 0

Detailed CVE Report: detailed-vulnerabilities-20251031-143022.csv
```

### Summary Report (JSON)

```json
{
  "scan_date": "2025-10-31T14:30:22-04:00",
  "namespace": "all",
  "severity_filter": "CRITICAL,HIGH",
  "total_images": 47,
  "results": [
    {
      "image": "quay.io/acm-d/search-api@sha256:def456",
      "status": "vulnerable",
      "vulnerabilities": {
        "critical": 2,
        "high": 5,
        "medium": 0,
        "low": 0,
        "unknown": 0
      }
    }
  ],
  "summary": {
    "scanned": 23,
    "clean": 22,
    "failed": 2,
    "total_vulnerabilities": {
      "critical": 15,
      "high": 42,
      "medium": 0,
      "low": 0,
      "unknown": 0
    }
  }
}
```

### Per-Image Report (with --detailed)

When using `--detailed`, each image gets its own report with full vulnerability details:

```json
{
  "SchemaVersion": 2,
  "ArtifactName": "quay.io/acm-d/search-api@sha256:...",
  "Results": [
    {
      "Target": "...",
      "Vulnerabilities": [
        {
          "VulnerabilityID": "CVE-2024-1234",
          "PkgName": "openssl",
          "InstalledVersion": "1.1.1k",
          "FixedVersion": "1.1.1l",
          "Severity": "CRITICAL",
          "Description": "...",
          "References": ["https://..."]
        }
      ]
    }
  ]
}
```

## Command-Line Options

### Required
None - all options have sensible defaults

### Optional

| Option | Default | Description |
|--------|---------|-------------|
| `-n, --namespace` | All namespaces | Scan only specified namespace |
| `-s, --severity` | `CRITICAL,HIGH` | Severity levels to report |
| `-f, --format` | `table` | Output format (table/json/sarif/cyclonedx/spdx) |
| `-o, --output-dir` | `./vulnerability-reports` | Directory for reports |
| `-t, --timeout` | `300` | Scan timeout per image (seconds) |
| `-i, --image-filter` | None | Only scan images matching pattern |
| `-p, --parallel` | `5` | Number of parallel scans |
| `-u, --include-unfixed` | `false` | Include vulnerabilities without fixes |
| `-d, --detailed` | `false` | Generate per-image reports |
| `--skip-trivy-check` | `false` | Skip Trivy installation check |
| `--trivy-db-repo` | Default | Custom Trivy DB repository URL |
| `--offline` | `false` | Offline scan mode |

## Exit Codes

- `0` - Scan completed, no CRITICAL or HIGH vulnerabilities found
- `1` - CRITICAL or HIGH vulnerabilities detected, or scan failed

## Working with CVE Details (CSV)

The CSV report is designed for analysis and remediation planning. Here are common tasks:

### Open in Spreadsheet

```bash
# Excel
open vulnerability-reports/detailed-vulnerabilities-*.csv

# Google Sheets
# Upload the CSV file through the web interface

# LibreOffice
libreoffice vulnerability-reports/detailed-vulnerabilities-*.csv
```

### Command-Line Analysis

```bash
# Find all CRITICAL CVEs
grep "CRITICAL" detailed-vulnerabilities-*.csv

# Count CVEs by severity
cut -d',' -f3 detailed-vulnerabilities-*.csv | sort | uniq -c

# List unique affected packages
cut -d',' -f5 detailed-vulnerabilities-*.csv | sort -u

# Find images with most CVEs
cut -d',' -f1 detailed-vulnerabilities-*.csv | sort | uniq -c | sort -rn

# Find vulnerabilities without fixes
grep "No fix available" detailed-vulnerabilities-*.csv

# Find high CVSS scores (>= 9.0)
awk -F',' '$4 >= 9.0 {print}' detailed-vulnerabilities-*.csv

# Extract CVEs for specific package (e.g., openssl)
grep -i "openssl" detailed-vulnerabilities-*.csv
```

### Database Import

```sql
-- PostgreSQL
CREATE TABLE vulnerabilities (
    image TEXT,
    cve_id TEXT,
    severity TEXT,
    cvss_score NUMERIC,
    package_name TEXT,
    installed_version TEXT,
    fixed_version TEXT,
    title TEXT
);

\COPY vulnerabilities FROM 'detailed-vulnerabilities-20251031-143022.csv' WITH CSV HEADER;

-- Query high-risk images
SELECT image, COUNT(*) as critical_count
FROM vulnerabilities
WHERE severity = 'CRITICAL'
GROUP BY image
ORDER BY critical_count DESC
LIMIT 10;

-- Find common vulnerabilities
SELECT cve_id, COUNT(DISTINCT image) as affected_images,
       MAX(cvss_score) as max_cvss
FROM vulnerabilities
WHERE severity IN ('CRITICAL', 'HIGH')
GROUP BY cve_id
ORDER BY affected_images DESC, max_cvss DESC;
```

### Python Analysis

```python
import pandas as pd

# Load CSV
df = pd.read_csv('detailed-vulnerabilities-20251031-143022.csv')

# Filter CRITICAL vulnerabilities
critical = df[df['Severity'] == 'CRITICAL']

# Sort by CVSS score
sorted_vulns = df.sort_values('CVSS Score', ascending=False)

# Group by image
by_image = df.groupby('Image').size().sort_values(ascending=False)

# Find unfixable CVEs
unfixable = df[df['Fixed Version'] == 'No fix available']

# Export filtered results
critical.to_excel('critical_cves.xlsx', index=False)
```

### Generate Remediation Report

```bash
#!/bin/bash
# Create a remediation plan

CSV_FILE="detailed-vulnerabilities-*.csv"

echo "# Vulnerability Remediation Plan"
echo ""
echo "## Images Requiring Immediate Action (CRITICAL CVEs)"
echo ""

# Group CRITICAL CVEs by image
grep "CRITICAL" "$CSV_FILE" | cut -d',' -f1 | sort -u | while read -r image; do
    echo "### $image"
    echo ""
    grep "$image" "$CSV_FILE" | grep "CRITICAL" | while IFS=, read -r img cve sev cvss pkg inst fix title; do
        echo "- **$cve** (CVSS: $cvss)"
        echo "  - Package: $pkg ($inst)"
        echo "  - Fix: Upgrade to $fix"
        echo ""
    done
done
```

## Use Cases

### 1. Pre-Release Scanning

Scan your cluster before a release to ensure no critical vulnerabilities:

```bash
./scan-cluster-vulnerabilities.sh \
  --namespace production \
  --severity CRITICAL,HIGH \
  --detailed

# Exit code 1 if vulnerabilities found - blocks release
```

### 2. Continuous Monitoring

Run periodic scans and track trends:

```bash
#!/bin/bash
# daily-scan.sh
./scan-cluster-vulnerabilities.sh \
  --format json \
  --output-dir /var/reports/$(date +%Y%m%d)

# Parse JSON to send alerts, create tickets, etc.
```

### 3. Compliance Reporting

Generate compliance reports in multiple formats:

```bash
# SARIF for GitHub Security
./scan-cluster-vulnerabilities.sh --format sarif

# SPDX/CycloneDX for SBOM requirements
./scan-cluster-vulnerabilities.sh --format cyclonedx
```

### 4. Targeted Scanning

Scan specific applications or teams:

```bash
# Scan only ACM operator images
./scan-cluster-vulnerabilities.sh --image-filter "acm-d"

# Scan only Red Hat certified images
./scan-cluster-vulnerabilities.sh --image-filter "registry.redhat.io"
```

### 5. Air-Gapped Environments

For disconnected clusters:

```bash
# 1. Download DB on connected system
trivy image --download-db-only

# 2. Copy ~/.cache/trivy to air-gapped system

# 3. Run offline scan
./scan-cluster-vulnerabilities.sh --offline
```

## Integration Examples

### GitLab CI/CD

```yaml
vulnerability-scan:
  stage: security
  script:
    - oc login --token=$OPENSHIFT_TOKEN --server=$OPENSHIFT_URL
    - ./scan-cluster-vulnerabilities.sh --namespace production --format json
  artifacts:
    reports:
      container_scanning: vulnerability-reports/*.json
  only:
    - schedules
```

### GitHub Actions

```yaml
name: Weekly Vulnerability Scan
on:
  schedule:
    - cron: '0 2 * * 1'  # Every Monday at 2 AM

jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Login to OpenShift
        run: oc login --token=${{ secrets.OC_TOKEN }} --server=${{ secrets.OC_SERVER }}
      - name: Scan Cluster
        run: |
          ./scan-cluster-vulnerabilities.sh \
            --severity CRITICAL,HIGH \
            --format sarif \
            --output-dir $GITHUB_WORKSPACE/reports
      - name: Upload SARIF
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: reports/*.sarif
```

### Jenkins Pipeline

```groovy
pipeline {
    agent any
    triggers {
        cron('H 2 * * *')  // Daily at 2 AM
    }
    stages {
        stage('Vulnerability Scan') {
            steps {
                sh '''
                    oc login --token=$OC_TOKEN --server=$OC_SERVER
                    ./scan-cluster-vulnerabilities.sh \
                        --namespace production \
                        --format json \
                        --output-dir reports
                '''
            }
        }
        stage('Parse Results') {
            steps {
                script {
                    def report = readJSON file: 'reports/vulnerability-summary-*.json'
                    if (report.summary.total_vulnerabilities.critical > 0) {
                        error("Critical vulnerabilities found!")
                    }
                }
            }
        }
    }
    post {
        always {
            archiveArtifacts artifacts: 'reports/**/*', fingerprint: true
        }
    }
}
```

## Troubleshooting

### Issue: Trivy Installation Fails

**Solution:**
```bash
# Install manually
curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b $HOME/.local/bin
export PATH="$HOME/.local/bin:$PATH"

# Skip auto-installation
./scan-cluster-vulnerabilities.sh --skip-trivy-check
```

### Issue: Scan Timeout

**Solution:**
```bash
# Increase timeout for large images
./scan-cluster-vulnerabilities.sh --timeout 600

# Or scan in smaller batches
./scan-cluster-vulnerabilities.sh --namespace specific-ns
```

### Issue: Too Many Images

**Solution:**
```bash
# Use filtering
./scan-cluster-vulnerabilities.sh --image-filter "myregistry.com"

# Scan namespaces separately
for ns in $(oc get ns -o name | cut -d/ -f2); do
  ./scan-cluster-vulnerabilities.sh --namespace $ns
done
```

### Issue: Rate Limiting (GitHub API)

**Solution:**
```bash
# Use custom DB repo
./scan-cluster-vulnerabilities.sh --trivy-db-repo myregistry.com/trivy-db

# Or use offline mode after initial download
trivy image --download-db-only
./scan-cluster-vulnerabilities.sh --offline
```

### Issue: jq Command Not Found

**Solution:**
```bash
# Install jq
# macOS
brew install jq

# RHEL/Fedora
sudo dnf install jq

# Ubuntu/Debian
sudo apt install jq
```

## Performance Considerations

### Scan Time Estimates

| Images | Time (default) | Time (parallel=10) |
|--------|----------------|-------------------|
| 10 | ~2-3 minutes | ~1-2 minutes |
| 50 | ~10-15 minutes | ~5-7 minutes |
| 100+ | ~30+ minutes | ~15-20 minutes |

### Optimization Tips

1. **Use Namespace Filtering**: Scan only relevant namespaces
2. **Increase Parallelism**: `--parallel 10` for faster scans
3. **Filter by Severity**: Skip LOW/MEDIUM if not needed
4. **Use Image Filtering**: Target specific registries
5. **Cache DB Updates**: Use `--offline` for subsequent scans

## Security Best Practices

1. **Regular Scanning**: Schedule weekly or daily scans
2. **Focus on CRITICAL/HIGH**: Address severe issues first
3. **Track Trends**: Compare reports over time
4. **Integrate with CI/CD**: Block deployments with critical CVEs
5. **Update Images**: Rebuild images with patched dependencies
6. **Document Exceptions**: Track accepted risks for unfixable CVEs

## Alternative Tools

If Trivy doesn't fit your needs, consider:

- **Grype**: Similar to Trivy, good alternative
  ```bash
  grype registry:image
  ```

- **Clair**: API-driven, integrated with Quay
  ```bash
  # Requires server setup
  clairctl report image
  ```

- **Snyk**: Commercial with free tier
  ```bash
  snyk container test image
  ```

- **RHACS**: Full security platform (commercial)
  - Real-time vulnerability detection
  - Policy enforcement
  - Network visualization

## References

- [Trivy Documentation](https://aquasecurity.github.io/trivy/)
- [OpenShift Security](https://docs.openshift.com/container-platform/latest/security/index.html)
- [CVE Database](https://cve.mitre.org/)
- [National Vulnerability Database](https://nvd.nist.gov/)

## License

This script is provided as-is for use with OpenShift clusters. Trivy is licensed under Apache 2.0.

## Support

For issues with:
- **This script**: Check troubleshooting section above
- **Trivy**: https://github.com/aquasecurity/trivy/issues
- **OpenShift**: Red Hat support channels
